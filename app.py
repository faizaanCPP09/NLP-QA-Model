import streamlit as st
from transformers import AutoTokenizer, AutoModelForQuestionAnswering, pipeline

@st.cache_resource
def load_model():
    tokenizer = AutoTokenizer.from_pretrained("./model")
    model = AutoModelForQuestionAnswering.from_pretrained("./model")
    return pipeline("question-answering", model=model, tokenizer=tokenizer)

qa_pipeline = load_model()

st.set_page_config(page_title="Multilingual QA", layout="centered")

st.markdown("""
    <h1 style='text-align: center; color: #3399ff;'>üåç Multilingual Question Answering BERT</h1>
    <p style='text-align: center; font-size: 18px;'>Ask questions in any language ‚Äî just give the context. Let the model do the thinking!</p>
""", unsafe_allow_html=True)

with st.form("qa_form"):
    context = st.text_area("üü¶ Enter the context:", height=200)
    question = st.text_input("‚ùì Enter your question:")
    submit = st.form_submit_button("Get Answer")

if submit:
    if not context or not question:
        st.warning("‚ö†Ô∏è Please enter both the context and question.")
    else:
        with st.spinner("ü§ñ Thinking..."):
            result = qa_pipeline(question=question, context=context)
            st.success(f"üß† **Answer:** {result['answer']}")